# ğŸ¦¾ ROS to LeRobot Dataset Converter

This repository provides a full pipeline to collect robot data from a ROS 2 system and convert it into the [LeRobot](https://github.com/huggingface/lerobot) dataset format, suitable for training vision-language-action models like SmolVLA or Pi-0.

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ data_collection/
        â””â”€â”€ data_collection.py                        # Collect data using ROS 2 and save to .pkl files
        â””â”€â”€  convert_dataset.py                      # Convert .pkl files to LeRobot-compatible Parquet and video files
        â””â”€â”€ generate_episodes_json.py           # Create episodes.jsonl and tasks.jsonl metadata files
        â””â”€â”€ generate_episodes_stats_json.py  # Compute per-episode statistics (mean, std, etc.)
        â””â”€â”€ generate_info_json.py                   # Generate dataset-level info.json
â”œâ”€â”€ my_dataset/                    # Raw data (output from data_collection.py)
â”œâ”€â”€ lerobot_dataset/               # Final formatted dataset (output of conversion)
```

---

## ğŸ“¦ Step-by-Step Instructions

### 1. Collect Data from ROS 2

Run the data collector node to save episodes in `.pkl` format.

```bash
python data_collection.py
```

- Input topics:
  - `/tf_right_wrist` â€” end-effector TF pose
  - `/joint_states_isaac` â€” hand joint states
  - `/hand_pose_ik` â€” IK-based hand pose
  - `/joint_command` â€” gripper command
  - `/rgb_left`, `/rgb_right` â€” camera images
  - `/recording_trigger` â€” control recording ("wait" or "stop")

- Output: Pickled episodes in `./my_dataset/episode_###.pkl`

---

### 2. Convert to LeRobot Format

Run the conversion script:

```bash
python convert_dataset.py
```

This will:
- Read `.pkl` files from `./my_dataset`
- Resize and encode images into MP4 videos
- Convert state/action data into Parquet tables
- Save them under `./lerobot_dataset/data/` and `./lerobot_dataset/videos/`

---

### 3. Generate Metadata

#### a) Generate `episodes.jsonl` and `tasks.jsonl`:

```bash
python generate_episodes_json.py
```

#### b) Generate `episodes_stats.jsonl`:

```bash
python generate_episodes_stats_json.py
```

#### c) Generate `info.json` (dataset description):

```bash
python generate_info_json.py
```

---

## ğŸ“Š Data Format

- `observation.state`: `[x, y, z, qx, qy, qz, qw, gripper]`
- `action`: same format as state
- `images.cam1` and `images.cam2`: RGB videos (360x640)
- Frame rate: 5 Hz

---

## âœ… Output Example

```
lerobot_dataset/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chunk-000/
â”‚       â””â”€â”€ episode_000000.parquet
â”œâ”€â”€ videos/
â”‚   â””â”€â”€ chunk-000/
â”‚       â”œâ”€â”€ observation.images.cam1/episode_000000.mp4
â”‚       â””â”€â”€ observation.images.cam2/episode_000000.mp4
â””â”€â”€ meta/
    â”œâ”€â”€ episodes.jsonl
    â”œâ”€â”€ tasks.jsonl
    â”œâ”€â”€ episodes_stats.jsonl
    â””â”€â”€ info.json
```

---

## ğŸ§  Notes

- The collected data is suitable for LeRobotâ€™s `SmolVLA` and `DiffusionPolicy` training pipelines.
- You can add new cameras or state dimensions by modifying the relevant `data_collection.py` logic and updating the metadata generator scripts accordingly.